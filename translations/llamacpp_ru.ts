<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE TS>
<TS version="2.1" language="ru">
<context>
    <name>LlamaCpp</name>
    <message>
        <location filename="../llamaplugin.cpp" line="+117"/>
        <source>llama.cpp coversation</source>
        <translation>чат llama.cpp</translation>
    </message>
    <message>
        <location line="+10"/>
        <source>Request llama.cpp Suggestion</source>
        <translation>Запросить предложение от llama.cpp</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Request llama.cpp suggestion at the current editor&apos;s cursor position.</source>
        <translation>Запросить предложение от llama.cpp в текущей позиции курсора редактора.</translation>
    </message>
    <message>
        <location line="+9"/>
        <source>Ctrl+G</source>
        <translation>Ctrl+G</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Toggle enable/disable llama.cpp</source>
        <translation>Включить/отключить llama.cpp</translation>
    </message>
    <message>
        <location line="+10"/>
        <source>Toggle Auto FIM</source>
        <translation>Включить/отключить автоматическое FIM</translation>
    </message>
    <message>
        <location line="+16"/>
        <source>Ctrl+Shift+G</source>
        <translation>Ctrl+Shift+G</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Disable llama.cpp.</source>
        <translation>Отключить llama.cpp.</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>Enable llama.cpp.</source>
        <translation>Включить llama.cpp.</translation>
    </message>
    <message>
        <location line="+362"/>
        <source>[llama.cpp] Error fetching fim completion from %1: %2</source>
        <translation>[llama.cpp] Ошибка получения завершения fim от %1: %2</translation>
    </message>
    <message>
        <location line="-427"/>
        <location filename="../llamaprojectpanel.cpp" line="+63"/>
        <source>llama.cpp</source>
        <translation>llama.cpp</translation>
    </message>
    <message>
        <location filename="../llamasettings.cpp" line="+18"/>
        <location line="+1"/>
        <source>Enable llama.cpp</source>
        <translation>Включить llama.cpp</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Enables the llama.cpp integration.</source>
        <translation>Включает интеграцию с llama.cpp.</translation>
    </message>
    <message>
        <location line="+18"/>
        <source>Endpoint</source>
        <translation>Конечная точка</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Endpoint:</source>
        <translation>Конечная точка:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>llama.cpp server endpoint</source>
        <translation>Конечная точка сервера llama.cpp</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>API Key</source>
        <translation>Ключ API</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>API Key:</source>
        <translation>Ключ API:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>llama.cpp server api key (optional)</source>
        <translation>Ключ API сервера llama.cpp (необязательно)</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Prefix Code Lines</source>
        <translation>Префиксные строки кода</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Prefix Code Lines:</source>
        <translation>Префиксные строки кода:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Number of code lines before the cursor location to include in the local prefix.</source>
        <translation>Количество строк кода перед позицией курсора, которые нужно включить в локальный префикс.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Suffix Code Lines</source>
        <translation>Суффиксные строки кода</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Suffix Code Lines:</source>
        <translation>Суффиксные строки кода:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Number of code lines after  the cursor location to include in the local suffix.</source>
        <translation>Количество строк кода после позиции курсора, которые нужно включить в локальный суффикс.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max Token Predictions</source>
        <translation>Максимальное количество предсказанных токенов</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Token Predictions:</source>
        <translation>Максимальное количество предсказанных токенов:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max number of tokens to predict.</source>
        <translation>Максимальное количество токенов для предсказания.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Stop Strings</source>
        <translation>Строки остановки</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Stop Strings:</source>
        <translation>Строки остановки:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Return the result immediately as soon as any of these strings are encountered in the generated text. Separated by semicolons.</source>
        <translation>Возвращать результат сразу, как только в сгенерированном тексте встретится любая из этих строк. Разделяются точками с запятой.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Max Prompt Time (ms)</source>
        <translation>Максимальное время обработки запроса (мс)</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Prompt Time (ms):</source>
        <translation>Максимальное время обработки запроса (мс):</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max alloted time for the prompt processing (TODO: not yet supported).</source>
        <translation>Максимальное время, отведенное на обработку запроса (TODO: пока не поддерживается).</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max Predict Time (ms)</source>
        <translation>Максимальное время предсказания (мс)</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Predict Time (ms):</source>
        <translation>Максимальное время предсказания (мс):</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max alloted time for the prediction.</source>
        <translation>Максимальное время, отведенное на предсказание.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Show Info</source>
        <translation>Показывать информацию</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Show Info:</source>
        <translation>Показывать информацию:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Show extra info about the inference (0 - disabled, 1 - statusline, 2 - inline).</source>
        <translation>Показывать дополнительную информацию о выводах (0 - отключено, 1 - строка состояния, 2 - встроенная).</translation>
    </message>
    <message>
        <location line="+3"/>
        <location line="+2"/>
        <source>Auto FIM</source>
        <translation>Автоматическое FIM</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Trigger FIM (Fill-in-the-Middle) completion automatically on cursor movement.</source>
        <translation>Автоматически запускать завершение FIM (Fill-in-the-Middle) при движении курсора.</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Line Suffix</source>
        <translation>Максимальный суффикс строки</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Line Suffix:</source>
        <translation>Максимальный суффикс строки:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Do not auto-trigger FIM completion if there are more than this number of characters to the right of the cursor.</source>
        <translation>Не запускать автоматически завершение FIM, если справа от курсора больше этого количества символов.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Max Cache Keys</source>
        <translation>Максимальное количество ключей кэша</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Cache Keys:</source>
        <translation>Максимальное количество ключей кэша:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max number of cached completions to keep in result_cache.</source>
        <translation>Максимальное количество завершений в кэше, которые нужно сохранять в result_cache.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Ring Chunks</source>
        <translation>Чанки кольца</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Ring Chunks:</source>
        <translation>Чанки кольца:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max number of chunks to pass as extra context to the server (0 to disable).</source>
        <translation>Максимальное количество чанков для передачи серверу в качестве дополнительного контекста (0 для отключения).</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Chunk Line Size</source>
        <translation>Размер чанка строк</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chunk Line Size:</source>
        <translation>Размер чанка строк:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max size of the chunks (in number of lines).&lt;br/&gt;&lt;br/&gt;Note: adjust these numbers so that you don&apos;t overrun your context. At ring_n_chunks = 64 and ring_chunk_size = 64 you need ~32k context.</source>
        <translation>Максимальный размер чанков (в количестве строк).&lt;br/&gt;&lt;br/&gt;Примечание: настройте эти числа так, чтобы не превышать лимит контекста. При ring_n_chunks = 64 и ring_chunk_size = 64 вам нужно ~32k контекста.</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Ring Line Scope</source>
        <translation>Область видимости строки кольца</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Ring Line Scope:</source>
        <translation>Область видимости строки кольца:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The range around the cursor position (in number of lines) for gathering chunks after FIM.</source>
        <translation>Диапазон вокруг позиции курсора (в количестве строк) для сбора чанков после FIM.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Update Interval (ms)</source>
        <translation>Интервал обновления (мс)</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Update Interval (ms):</source>
        <translation>Интервал обновления (мс):</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>How often to process queued chunks in normal mode.</source>
        <translation>Как часто обрабатывать очереди чанков в обычном режиме.</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Chat Endpoint</source>
        <translation>Конечная точка чата</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chat Endpoint:</source>
        <translation>Конечная точка чата:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>llama.cpp server chat endpoint</source>
        <translation>Конечная точка чата сервера llama.cpp</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Chat API Key</source>
        <translation>Ключ API чата</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chat API Key:</source>
        <translation>Ключ API чата:</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Set the API Key if you are using --api-key option for the server.</source>
        <translation>Установите ключ API, если вы используете опцию --api-key для сервера.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>System Message</source>
        <translation>Системное сообщение</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>System Message:</source>
        <translation>Системное сообщение:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Default: none</source>
        <translation>По умолчанию: нет</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The starting message that defines how model should behave. Will be disabled if left empty.</source>
        <translation>Начальное сообщение, определяющее, как модель должна себя вести. Будет отключено, если оставлено пустым.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Paste Long Text to File Length</source>
        <translation>Длина файла при вставке длинного текста</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Paste Long Text to File Length:</source>
        <translation>Длина файла при вставке длинного текста:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>On pasting long text, it will be converted to a file. You can control the file length by setting the value of this parameter. Value 0 means disable.</source>
        <translation>При вставке длинного текста он будет преобразован в файл. Вы можете контролировать длину файла, установив значение этого параметра. Значение 0 означает отключение.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Samplers</source>
        <translation>Семплеры</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Samplers:</source>
        <translation>Семплеры:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>The order at which samplers are applied, in simplified way. Default is &quot;edkypmxt&quot;: dry-&gt;top_k-&gt;typ_p-&gt;top_p-&gt;min_p-&gt;xtc-&gt;temperature</source>
        <translation>Порядок применения семплеров. По умолчанию: "edkypmxt": dry-&gt;top_k-&gt;typ_p-&gt;top_p-&gt;min_p-&gt;xtc-&gt;temperature</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Temperature</source>
        <translation>Температура</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Temperature:</source>
        <translation>Температура:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Controls the randomness of the generated text by affecting the probability distribution of the output tokens. Higher = more random, lower = more focused.</source>
        <translation>Контролирует случайность сгенерированного текста, влияя на распределение вероятностей выходных токенов. Более высокое значение = более случайный текст, более низкое = более сфокусированный.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Dynamic Temperature Range</source>
        <translation>Диапазон динамической температуры</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Dynamic Temperature Range:</source>
        <translation>Диапазон динамической температуры:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Addon for the temperature sampler. The added value to the range of dynamic temperature, which adjusts probabilities by entropy of tokens.</source>
        <translation>Дополнение для семплера температуры. Добавленное значение к диапазону динамической температуры, которое корректирует вероятности по энтропии токенов.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Dynamic Temperature Exponent</source>
        <translation>Показатель динамической температуры</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Dynamic Temperature Exponent:</source>
        <translation>Показатель динамической температуры:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Addon for the temperature sampler. Smoothes out the probability redistribution based on the most probable token.</source>
        <translation>Дополнение для семплера температуры. Сглаживает перераспределение вероятностей на основе наиболее вероятного токена.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Top K</source>
        <translation>Top K</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Top K:</source>
        <translation>Top K:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Keeps only k top tokens.</source>
        <translation>Оставляет только k топовых токенов.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Top P</source>
        <translation>Top P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Top P:</source>
        <translation>Top P:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens to those that together have a cumulative probability of at least p</source>
        <translation>Ограничивает токены теми, которые вместе имеют кумулятивную вероятность не менее p</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Min P</source>
        <translation>Min P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Min P:</source>
        <translation>Min P:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Limits tokens based on the minimum probability for a token to be considered, relative to the probability of the most likely token.</source>
        <translation>Ограничивает токены на основе минимальной вероятности для токена, который следует учитывать, относительно вероятности наиболее вероятного токена.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>XTC Probability</source>
        <translation>Вероятность XTC</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>XTC Probability:</source>
        <translation>Вероятность XTC:</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC.</source>
        <translation>Семплер XTC вырезает топовые токены; этот параметр контролирует вероятность вырезания токенов вообще. 0 отключает XTC.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>XTC Threshold</source>
        <translation>Порог XTC</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>XTC Threshold:</source>
        <translation>Порог XTC:</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token.</source>
        <translation>Семплер XTC вырезает топовые токены; этот параметр контролирует вероятность токена, при которой этот токен будет вырезан.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Typical P</source>
        <translation>Типичная P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Typical P:</source>
        <translation>Типичная P:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Sorts and limits tokens based on the difference between log-probability and entropy.</source>
        <translation>Сортирует и ограничивает токены на основе разницы между логарифмической вероятностью и энтропией.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Repeat Last N</source>
        <translation>Последние N повторений</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Repeat Last N:</source>
        <translation>Последние N повторений:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Last n tokens to consider for penalizing repetition</source>
        <translation>Последние n токенов для учета при наказании за повторение</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Repeat Penalty</source>
        <translation>Штраф за повторение</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Repeat Penalty:</source>
        <translation>Штраф за повторение:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Controls the repetition of token sequences in the generated text</source>
        <translation>Контролирует повторение последовательностей токенов в сгенерированном тексте</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Presence Penalty</source>
        <translation>Штраф за присутствие</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Presence Penalty:</source>
        <translation>Штраф за присутствие:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens based on whether they appear in the output or not.</source>
        <translation>Ограничивает токены на основе того, появляются ли они в выводе или нет.</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Frequency Penalty</source>
        <translation>Штраф за частоту</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Frequency Penalty:</source>
        <translation>Штраф за частоту:</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens based on how often they appear in the output.</source>
        <translation>Ограничивает токены на основе того, как часто они появляются в выводе.</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Multiplier</source>
        <translation>Множитель DRY</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Multiplier:</source>
        <translation>Множитель DRY:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier.</source>
        <translation>Сепмлирование DRY снижает повторение в сгенерированном тексте даже в длинных контекстах. Этот параметр устанавливает множитель семплирования DRY.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Base</source>
        <translation>Базовое значение DRY</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Base:</source>
        <translation>Базовое значение DRY:</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value.</source>
        <translation>Сепмлирование DRY снижает повторение в сгенерированном тексте даже в длинных контекстах. Этот параметр устанавливает базовое значение семплирования DRY.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Allowed Length</source>
        <translation>Разрешенная длина DRY</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Allowed Length:</source>
        <translation>Разрешенная длина DRY:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling.</source>
        <translation>Сепмлирование DRY снижает повторение в сгенерированном тексте даже в длинных контекстах. Этот параметр устанавливает разрешенную длину для семплирования DRY.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Penalty Last N</source>
        <translation>Штраф DRY за последние N</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Penalty Last N:</source>
        <translation>Штраф DRY за последние N:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens.</source>
        <translation>Сепмлирование DRY снижает повторение в сгенерированном тексте даже в длинных контекстах. Этот параметр устанавливает штраф DRY за последние n токенов.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Max Tokens</source>
        <translation>Максимальное количество токенов</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Tokens:</source>
        <translation>Максимальное количество токенов:</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The maximum number of token per output. -1 means no limit.</source>
        <translation>Максимальное количество токенов на вывод. -1 означает отсутствие ограничения.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Custom JSON config</source>
        <translation>Пользовательская JSON конфигурация</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Custom JSON config:</source>
        <translation>Пользовательская JSON конфигурация:</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Custom JSON string of extra parameters.</source>
        <translation>Пользовательская JSON строка дополнительных параметров.</translation>
    </message>
    <message>
        <location line="+4"/>
        <location line="+2"/>
        <source>Show Tokens Per Second</source>
        <translation>Показывать токены в секунду</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Show tokens per second in the chat UI.</source>
        <translation>Показывать токены в секунду в интерфейсе чата.</translation>
    </message>
    <message>
        <location filename="../llamachateditor.cpp" line="+219"/>
        <source>Search in chat</source>
        <translation>Поиск в чате</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Next search result</source>
        <translation>Следующий результат поиска</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Previous search result</source>
        <translation>Предыдущий результат поиска</translation>
    </message>
    <message>
        <location line="+44"/>
        <source>Model Path: %1</source>
        <translation>Путь к модели: %1</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Context: %L1</source>
        <translation>Контекст: %L1</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Vision: %1</source>
        <translation>Видение: %1</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>yes</source>
        <translation>да</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>no</source>
        <translation>нет</translation>
    </message>
    <message>
        <location line="+35"/>
        <source>Follow‑up questions:</source>
        <translation>Дополнительные вопросы:</translation>
    </message>
    <message>
        <location line="+477"/>
        <source>Speed: %1 t/s</source>
        <translation>Скорость: %1 т/с</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>&lt;b&gt;Prompt:&lt;/b&gt;&lt;br&gt;Tokens: %1&lt;br&gt;Time: %2 ms&lt;br&gt;Speed: %3 t/s&lt;br&gt;&lt;br&gt;&lt;b&gt;Generation:&lt;/b&gt;&lt;br&gt;Tokens: %4&lt;br&gt;Time: %5 ms&lt;br&gt;Speed: %6 t/s</source>
        <translation>&lt;b&gt;Запрос:&lt;/b&gt;&lt;br&gt;Токены: %1&lt;br&gt;Время: %2 мс&lt;br&gt;Скорость: %3 т/с&lt;br&gt;&lt;br&gt;&lt;b&gt;Генерация:&lt;/b&gt;&lt;br&gt;Токены: %4&lt;br&gt;Время: %5 мс&lt;br&gt;Скорость: %6 т/с</translation>
    </message>
    <message>
        <location line="+43"/>
        <source>LlamaCpp Chat Editor</source>
        <translation>Редактор чата LlamaCpp</translation>
    </message>
    <message>
        <location filename="../llamachatinput.cpp" line="+73"/>
        <source>Type a message (Shift+Enter for new line)</source>
        <translation>Введите сообщение (Shift+Enter для новой строки)</translation>
    </message>
    <message>
        <location line="+12"/>
        <source>Attach file</source>
        <translation>Прикрепить файл</translation>
    </message>
    <message>
        <location line="+54"/>
        <source>Stop assistant answer generation</source>
        <translation>Остановить генерацию ответа ассистента</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Send message to assistant</source>
        <translation>Отправить сообщение ассистенту</translation>
    </message>
    <message>
        <location filename="../llamachatmessage.cpp" line="+71"/>
        <location line="+203"/>
        <source>Thought Process</source>
        <translation>Процесс мышления</translation>
    </message>
    <message>
        <location line="-202"/>
        <source>Click to expand / hide the thought process</source>
        <translation>Нажмите, чтобы развернуть/скрыть процесс мышления</translation>
    </message>
    <message>
        <location line="+41"/>
        <source>Attached files</source>
        <translation>Прикрепленные файлы</translation>
    </message>
    <message>
        <location line="+74"/>
        <source>Go to previous message</source>
        <translation>Перейти к предыдущему сообщению</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Go to next message</source>
        <translation>Перейти к следующему сообщению</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>Edit the message</source>
        <translation>Редактировать сообщение</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Re-generate the answer</source>
        <translation>Перегенерировать ответ</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Copy the message to clipboard</source>
        <translation>Копировать сообщение в буфер обмена</translation>
    </message>
    <message>
        <location line="+54"/>
        <source>Thinking %1</source>
        <translation>Думайте %1</translation>
    </message>
    <message>
        <location line="+208"/>
        <source>Overwrite File?</source>
        <translation>Перезаписать файл?</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>The file &quot;%1&quot; already exists.

Do you want to overwrite it?</source>
        <translation>Файл &quot;%1&quot; уже существует.

Вы хотите его перезаписать?</translation>
    </message>
    <message>
        <location line="+21"/>
        <source>Save File</source>
        <translation>Сохранить файл</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>All Files (*)</source>
        <translation>Все файлы (*)</translation>
    </message>
    <message>
        <location filename="../llamaconversationsmodel.cpp" line="+73"/>
        <source>Name</source>
        <translation>Имя</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Date</source>
        <translation>Дата</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Conversation Id</source>
        <translation>Идентификатор разговора</translation>
    </message>
    <message>
        <location filename="../llamaconversationsview.cpp" line="+111"/>
        <source>Creates a new llama.cpp conversation</source>
        <translation>Создать новый разговор llama.cpp</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Refresh</source>
        <translation>Обновить</translation>
    </message>
    <message>
        <location line="+114"/>
        <source>Rename...</source>
        <translation>Переименовать...</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Summarize</source>
        <translation>Сводка</translation>
    </message>
    <message>
        <location line="+1"/>
        <location line="+40"/>
        <source>Delete</source>
        <translation>Удалить</translation>
    </message>
    <message>
        <location line="-39"/>
        <source>Save as Markdown</source>
        <translation>Сохранить как Markdown</translation>
    </message>
    <message>
        <location line="+32"/>
        <source>Delete Conversation</source>
        <translation>Удалить разговор</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Are you sure you want to delete the conversation:
%1</source>
        <translation>Вы уверены, что хотите удалить разговор:
%1</translation>
    </message>
    <message>
        <location line="+74"/>
        <source>Save Conversation as Markdown</source>
        <translation>Сохранить разговор как Markdown</translation>
    </message>
    <message>
        <location line="+12"/>
        <source>Error</source>
        <translation>Ошибка</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Cannot write file:
%1</source>
        <translation>Не удалось записать файл:
%1</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>llama.cpp Conversations</source>
        <translation>Разговоры llama.cpp</translation>
    </message>
    <message>
        <location filename="../llamalocatorfilter.cpp" line="+43"/>
        <source>Create a summary of {selection}</source>
        <translation>Создать сводку выделенного</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Create a commit message for {selection}</source>
        <translation>Создать сообщение коммита для выделенного</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Explain the code in {selection}</source>
        <translation>Объяснить код в выделении</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Do spell checking and fix any typos in {selection}</source>
        <translation>Проверить орфографию и исправить опечатки в выделении</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Generate test cases for {selection}. Output only code. No explanations</source>
        <translation>Сгенерировать тестовые примеры для выделенного. Выводить только код. Без объяснений</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Update translation in {selection}. Provide the full translation file as output</source>
        <translation>Обновить перевод в выделении. Предоставить полный файл перевода в качестве вывода</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>Send the current selection to llama.cpp with a prompt.
Built‑in prompts: %1
You can type any other prompt – they are remembered for next time.</source>
        <translation>Отправить текущее выделение в llama.cpp с запросом.
Встроенные запросы: %1
Вы можете ввести любой другой запрос – они запоминаются на следующий раз.</translation>
    </message>
    <message>
        <location filename="../llamamarkdownwidget.cpp" line="+107"/>
        <source>Copy the code below to Clipboard</source>
        <translation>Копировать код ниже в буфер обмена</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Save the code below into a file on disk</source>
        <translation>Сохранить код ниже в файл на диске</translation>
    </message>
    <message>
        <location line="+282"/>
        <location line="+10"/>
        <source>Copy</source>
        <translation>Копировать</translation>
    </message>
    <message>
        <location line="-9"/>
        <location line="+10"/>
        <source>Save</source>
        <translation>Сохранить</translation>
    </message>
    <message>
        <location filename="../llamaplugin.h" line="+118"/>
        <source>New Conversation</source>
        <translation>Новый разговор</translation>
    </message>
    <message>
        <location filename="../llamasearchtoolbar.cpp" line="+22"/>
        <source>Search</source>
        <translation>Поиск</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Find ...</source>
        <translation>Найти...</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Previous result</source>
        <translation>Предыдущий результат</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Next result</source>
        <translation>Следующий результат</translation>
    </message>
</context>
</TS>
