<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE TS>
<TS version="2.1" language="fr_FR">
<context>
    <name>LlamaCpp</name>
    <message>
        <location filename="../llamaplugin.cpp" line="+117"/>
        <source>llama.cpp coversation</source>
        <translation>Conversation llama.cpp</translation>
    </message>
    <message>
        <location line="+10"/>
        <source>Request llama.cpp Suggestion</source>
        <translation>Demander une suggestion llama.cpp</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Request llama.cpp suggestion at the current editor&apos;s cursor position.</source>
        <translation>Demander une suggestion llama.cpp à la position du curseur dans l'éditeur actuel.</translation>
    </message>
    <message>
        <location line="+9"/>
        <source>Ctrl+G</source>
        <translation>Ctrl+G</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Toggle enable/disable llama.cpp</source>
        <translation>Activer/désactiver llama.cpp</translation>
    </message>
    <message>
        <location line="+10"/>
        <source>Toggle Auto FIM</source>
        <translation>Activer/désactiver le FIM automatique</translation>
    </message>
    <message>
        <location line="+16"/>
        <source>Ctrl+Shift+G</source>
        <translation>Ctrl+Maj+G</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Disable llama.cpp.</source>
        <translation>Désactiver llama.cpp.</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>Enable llama.cpp.</source>
        <translation>Activer llama.cpp.</translation>
    </message>
    <message>
        <location line="+362"/>
        <source>[llama.cpp] Error fetching fim completion from %1: %2</source>
        <translation>[llama.cpp] Erreur lors de la récupération de la complétion FIM depuis %1 : %2</translation>
    </message>
    <message>
        <location line="-427"/>
        <location filename="../llamaprojectpanel.cpp" line="+63"/>
        <source>llama.cpp</source>
        <translation>llama.cpp</translation>
    </message>
    <message>
        <location filename="../llamasettings.cpp" line="+18"/>
        <location line="+1"/>
        <source>Enable llama.cpp</source>
        <translation>Activer llama.cpp</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Enables the llama.cpp integration.</source>
        <translation>Active l'intégration de llama.cpp.</translation>
    </message>
    <message>
        <location line="+18"/>
        <source>Endpoint</source>
        <translation>Point de terminaison</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Endpoint:</source>
        <translation>Point de terminaison :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>llama.cpp server endpoint</source>
        <translation>Point de terminaison du serveur llama.cpp</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>API Key</source>
        <translation>Clé API</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>API Key:</source>
        <translation>Clé API :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>llama.cpp server api key (optional)</source>
        <translation>Clé API du serveur llama.cpp (facultatif)</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Prefix Code Lines</source>
        <translation>Lignes de code en préfixe</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Prefix Code Lines:</source>
        <translation>Lignes de code en préfixe :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Number of code lines before the cursor location to include in the local prefix.</source>
        <translation>Nombre de lignes de code avant la position du curseur à inclure dans le préfixe local.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Suffix Code Lines</source>
        <translation>Lignes de code en suffixe</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Suffix Code Lines:</source>
        <translation>Lignes de code en suffixe :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Number of code lines after the cursor location to include in the local suffix.</source>
        <translation>Nombre de lignes de code après la position du curseur à inclure dans le suffixe local.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max Token Predictions</source>
        <translation>Nombre maximal de prédictions de jetons</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Token Predictions:</source>
        <translation>Nombre maximal de prédictions de jetons :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max number of tokens to predict.</source>
        <translation>Nombre maximal de jetons à prédire.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Stop Strings</source>
        <translation>Chaînes d'arrêt</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Stop Strings:</source>
        <translation>Chaînes d'arrêt :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Return the result immediately as soon as any of these strings are encountered in the generated text. Separated by semicolons.</source>
        <translation>Retourne le résultat immédiatement dès qu'une de ces chaînes est rencontrée dans le texte généré. Séparées par des points-virgules.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Max Prompt Time (ms)</source>
        <translation>Temps maximal de traitement de la requête (ms)</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Prompt Time (ms):</source>
        <translation>Temps maximal de traitement de la requête (ms) :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max alloted time for the prompt processing (TODO: not yet supported).</source>
        <translation>Temps maximal alloué pour le traitement de la requête (TODO : non encore pris en charge).</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max Predict Time (ms)</source>
        <translation>Temps maximal de prédiction (ms)</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Predict Time (ms):</source>
        <translation>Temps maximal de prédiction (ms) :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max alloted time for the prediction.</source>
        <translation>Temps maximal alloué pour la prédiction.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Show Info</source>
        <translation>Afficher les informations</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Show Info:</source>
        <translation>Afficher les informations :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Show extra info about the inference (0 - disabled, 1 - statusline, 2 - inline).</source>
        <translation>Afficher des informations supplémentaires sur l'inférence (0 - désactivé, 1 - barre d'état, 2 - en ligne).</translation>
    </message>
    <message>
        <location line="+3"/>
        <location line="+2"/>
        <source>Auto FIM</source>
        <translation>FIM automatique</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Trigger FIM (Fill-in-the-Middle) completion automatically on cursor movement.</source>
        <translation>Déclencher automatiquement la complétion FIM (Fill-in-the-Middle) lors du déplacement du curseur.</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Line Suffix</source>
        <translation>Suffixe maximal de ligne</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Line Suffix:</source>
        <translation>Suffixe maximal de ligne :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Do not auto-trigger FIM completion if there are more than this number of characters to the right of the cursor.</source>
        <translation>Ne pas déclencher automatiquement la complétion FIM s'il y a plus de caractères à droite du curseur que ce nombre.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Max Cache Keys</source>
        <translation>Nombre maximal de clés de cache</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Cache Keys:</source>
        <translation>Nombre maximal de clés de cache :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max number of cached completions to keep in result_cache.</source>
        <translation>Nombre maximal de complétions mises en cache à conserver dans result_cache.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Ring Chunks</source>
        <translation>Chunks en anneau</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Ring Chunks:</source>
        <translation>Chunks en anneau :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max number of chunks to pass as extra context to the server (0 to disable).</source>
        <translation>Nombre maximal de chunks à passer comme contexte supplémentaire au serveur (0 pour désactiver).</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Chunk Line Size</source>
        <translation>Taille des chunks en lignes</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chunk Line Size:</source>
        <translation>Taille des chunks en lignes :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max size of the chunks (in number of lines).&lt;br/&gt;&lt;br/&gt;Note: adjust these numbers so that you don&apos;t overrun your context. At ring_n_chunks = 64 and ring_chunk_size = 64 you need ~32k context.</source>
        <translation>Taille maximale des chunks (en nombre de lignes).&lt;br/&gt;&lt;br/&gt;Remarque : ajustez ces nombres pour ne pas dépasser votre contexte. Avec ring_n_chunks = 64 et ring_chunk_size = 64, vous avez besoin d'environ 32 ko de contexte.</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Ring Line Scope</source>
        <translation>Portée des lignes en anneau</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Ring Line Scope:</source>
        <translation>Portée des lignes en anneau :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The range around the cursor position (in number of lines) for gathering chunks after FIM.</source>
        <translation>La plage autour de la position du curseur (en nombre de lignes) pour rassembler les chunks après FIM.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Update Interval (ms)</source>
        <translation>Intervalle de mise à jour (ms)</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Update Interval (ms):</source>
        <translation>Intervalle de mise à jour (ms) :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>How often to process queued chunks in normal mode.</source>
        <translation>Fréquence de traitement des chunks en attente en mode normal.</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Chat Endpoint</source>
        <translation>Point de terminaison de chat</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chat Endpoint:</source>
        <translation>Point de terminaison de chat :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>llama.cpp server chat endpoint</source>
        <translation>Point de terminaison de chat du serveur llama.cpp</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Chat API Key</source>
        <translation>Clé API de chat</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chat API Key:</source>
        <translation>Clé API de chat :</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Set the API Key if you are using --api-key option for the server.</source>
        <translation>Définir la clé API si vous utilisez l'option --api-key pour le serveur.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>System Message</source>
        <translation>Message système</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>System Message:</source>
        <translation>Message système :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Default: none</source>
        <translation>Par défaut : aucun</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The starting message that defines how model should behave. Will be disabled if left empty.</source>
        <translation>Le message de départ qui définit comment le modèle doit se comporter. Sera désactivé s'il est laissé vide.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Paste Long Text to File Length</source>
        <translation>Longueur de collage de texte long dans un fichier</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Paste Long Text to File Length:</source>
        <translation>Longueur de collage de texte long dans un fichier :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>On pasting long text, it will be converted to a file. You can control the file length by setting the value of this parameter. Value 0 means disable.</source>
        <translation>Lors du collage de texte long, il sera converti en fichier. Vous pouvez contrôler la longueur du fichier en définissant la valeur de ce paramètre. La valeur 0 signifie désactiver.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Samplers</source>
        <translation>Échantillonneurs</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Samplers:</source>
        <translation>Échantillonneurs :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>The order at which samplers are applied, in simplified way. Default is &quot;edkypmxt&quot;: dry-&gt;top_k-&gt;typ_p-&gt;top_p-&gt;min_p-&gt;xtc-&gt;temperature</source>
        <translation>L'ordre dans lequel les échantillonneurs sont appliqués, de manière simplifiée. Par défaut : &quot;edkypmxt&quot; : dry-&gt;top_k-&gt;typ_p-&gt;top_p-&gt;min_p-&gt;xtc-&gt;temperature</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Temperature</source>
        <translation>Température</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Temperature:</source>
        <translation>Température :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Controls the randomness of the generated text by affecting the probability distribution of the output tokens. Higher = more random, lower = more focused.</source>
        <translation>Contrôle l'aléatoire du texte généré en affectant la distribution de probabilité des jetons de sortie. Plus élevé = plus aléatoire, plus bas = plus focalisé.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Dynamic Temperature Range</source>
        <translation>Plage de température dynamique</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Dynamic Temperature Range:</source>
        <translation>Plage de température dynamique :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Addon for the temperature sampler. The added value to the range of dynamic temperature, which adjusts probabilities by entropy of tokens.</source>
        <translation>Extension pour l'échantillonneur de température. La valeur ajoutée à la plage de température dynamique, qui ajuste les probabilités par l'entropie des jetons.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Dynamic Temperature Exponent</source>
        <translation>Exposant de température dynamique</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Dynamic Temperature Exponent:</source>
        <translation>Exposant de température dynamique :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Addon for the temperature sampler. Smoothes out the probability redistribution based on the most probable token.</source>
        <translation>Extension pour l'échantillonneur de température. Lisse la redistribution des probabilités en fonction du jeton le plus probable.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Top K</source>
        <translation>Top K</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Top K:</source>
        <translation>Top K :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Keeps only k top tokens.</source>
        <translation>Conserve uniquement les k jetons les plus probables.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Top P</source>
        <translation>Top P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Top P:</source>
        <translation>Top P :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens to those that together have a cumulative probability of at least p</source>
        <translation>Limite les jetons à ceux dont la probabilité cumulative est d'au moins p</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Min P</source>
        <translation>Min P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Min P:</source>
        <translation>Min P :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Limits tokens based on the minimum probability for a token to be considered, relative to the probability of the most likely token.</source>
        <translation>Limite les jetons en fonction de la probabilité minimale pour qu'un jeton soit pris en compte, par rapport à la probabilité du jeton le plus probable.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>XTC Probability</source>
        <translation>Probabilité XTC</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>XTC Probability:</source>
        <translation>Probabilité XTC :</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC.</source>
        <translation>L'échantillonneur XTC élimine les jetons les plus probables ; ce paramètre contrôle la probabilité d'éliminer des jetons. 0 désactive XTC.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>XTC Threshold</source>
        <translation>Seuil XTC</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>XTC Threshold:</source>
        <translation>Seuil XTC :</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token.</source>
        <translation>L'échantillonneur XTC élimine les jetons les plus probables ; ce paramètre contrôle la probabilité d'un jeton nécessaire pour l'éliminer.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Typical P</source>
        <translation>Typical P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Typical P:</source>
        <translation>Typical P :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Sorts and limits tokens based on the difference between log-probability and entropy.</source>
        <translation>Trie et limite les jetons en fonction de la différence entre la log-probabilité et l'entropie.</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Repeat Last N</source>
        <translation>Répéter les N derniers</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Repeat Last N:</source>
        <translation>Répéter les N derniers :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Last n tokens to consider for penalizing repetition</source>
        <translation>Derniers n jetons à prendre en compte pour pénaliser la répétition</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Repeat Penalty</source>
        <translation>Pénalité de répétition</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Repeat Penalty:</source>
        <translation>Pénalité de répétition :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Controls the repetition of token sequences in the generated text</source>
        <translation>Contrôle la répétition des séquences de jetons dans le texte généré</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Presence Penalty</source>
        <translation>Pénalité de présence</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Presence Penalty:</source>
        <translation>Pénalité de présence :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens based on whether they appear in the output or not.</source>
        <translation>Limite les jetons en fonction de leur apparition dans la sortie.</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Frequency Penalty</source>
        <translation>Pénalité de fréquence</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Frequency Penalty:</source>
        <translation>Pénalité de fréquence :</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens based on how often they appear in the output.</source>
        <translation>Limite les jetons en fonction de leur fréquence d'apparition dans la sortie.</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Multiplier</source>
        <translation>Multiplicateur DRY</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Multiplier:</source>
        <translation>Multiplicateur DRY :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier.</source>
        <translation>L'échantillonnage DRY réduit la répétition dans le texte généré même sur de longs contextes. Ce paramètre définit le multiplicateur d'échantillonnage DRY.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Base</source>
        <translation>Base DRY</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Base:</source>
        <translation>Base DRY :</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value.</source>
        <translation>L'échantillonnage DRY réduit la répétition dans le texte généré même sur de longs contextes. Ce paramètre définit la valeur de base de l'échantillonnage DRY.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Allowed Length</source>
        <translation>Longueur autorisée DRY</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Allowed Length:</source>
        <translation>Longueur autorisée DRY :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling.</source>
        <translation>L'échantillonnage DRY réduit la répétition dans le texte généré même sur de longs contextes. Ce paramètre définit la longueur autorisée pour l'échantillonnage DRY.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Penalty Last N</source>
        <translation>Pénalité DRY pour les N derniers</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Penalty Last N:</source>
        <translation>Pénalité DRY pour les N derniers :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens.</source>
        <translation>L'échantillonnage DRY réduit la répétition dans le texte généré même sur de longs contextes. Ce paramètre définit la pénalité DRY pour les n derniers jetons.</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Max Tokens</source>
        <translation>Nombre maximal de jetons</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Tokens:</source>
        <translation>Nombre maximal de jetons :</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The maximum number of token per output. -1 means no limit.</source>
        <translation>Le nombre maximal de jetons par sortie. -1 signifie sans limite.</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Custom JSON config</source>
        <translation>Configuration JSON personnalisée</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Custom JSON config:</source>
        <translation>Configuration JSON personnalisée :</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Custom JSON string of extra parameters.</source>
        <translation>Chaîne JSON personnalisée de paramètres supplémentaires.</translation>
    </message>
    <message>
        <location line="+4"/>
        <location line="+2"/>
        <source>Show Tokens Per Second</source>
        <translation>Afficher les jetons par seconde</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Show tokens per second in the chat UI.</source>
        <translation>Afficher les jetons par seconde dans l'interface de chat.</translation>
    </message>
    <message>
        <location filename="../llamachateditor.cpp" line="+219"/>
        <source>Search in chat</source>
        <translation>Rechercher dans le chat</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Next search result</source>
        <translation>Résultat de recherche suivant</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Previous search result</source>
        <translation>Résultat de recherche précédent</translation>
    </message>
    <message>
        <location line="+44"/>
        <source>Model Path: %1</source>
        <translation>Chemin du modèle : %1</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Context: %L1</source>
        <translation>Contexte : %L1</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Vision: %1</source>
        <translation>Vision : %1</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>yes</source>
        <translation>oui</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>no</source>
        <translation>non</translation>
    </message>
    <message>
        <location line="+35"/>
        <source>Follow‑up questions:</source>
        <translation>Questions complémentaires :</translation>
    </message>
    <message>
        <location line="+477"/>
        <source>Speed: %1 t/s</source>
        <translation>Vitesse : %1 j/s</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>&lt;b&gt;Prompt:&lt;/b&gt;&lt;br&gt;Tokens: %1&lt;br&gt;Time: %2 ms&lt;br&gt;Speed: %3 t/s&lt;br&gt;&lt;br&gt;&lt;b&gt;Generation:&lt;/b&gt;&lt;br&gt;Tokens: %4&lt;br&gt;Time: %5 ms&lt;br&gt;Speed: %6 t/s</source>
        <translation>&lt;b&gt;Invite :&lt;/b&gt;&lt;br&gt;Jetons : %1&lt;br&gt;Temps : %2 ms&lt;br&gt;Vitesse : %3 j/s&lt;br&gt;&lt;br&gt;&lt;b&gt;Génération :&lt;/b&gt;&lt;br&gt;Jetons : %4&lt;br&gt;Temps : %5 ms&lt;br&gt;Vitesse : %6 j/s</translation>
    </message>
    <message>
        <location line="+43"/>
        <source>LlamaCpp Chat Editor</source>
        <translation>Éditeur de chat LlamaCpp</translation>
    </message>
    <message>
        <location filename="../llamachatinput.cpp" line="+73"/>
        <source>Type a message (Shift+Enter for new line)</source>
        <translation>Saisir un message (Maj+Entrée pour une nouvelle ligne)</translation>
    </message>
    <message>
        <location line="+12"/>
        <source>Attach file</source>
        <translation>Joindre un fichier</translation>
    </message>
    <message>
        <location line="+54"/>
        <source>Stop assistant answer generation</source>
        <translation>Arrêter la génération de réponse de l'assistant</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Send message to assistant</source>
        <translation>Envoyer le message à l'assistant</translation>
    </message>
    <message>
        <location filename="../llamachatmessage.cpp" line="+71"/>
        <location line="+203"/>
        <source>Thought Process</source>
        <translation>Processus de pensée</translation>
    </message>
    <message>
        <location line="-202"/>
        <source>Click to expand / hide the thought process</source>
        <translation>Cliquez pour développer/masquer le processus de pensée</translation>
    </message>
    <message>
        <location line="+41"/>
        <source>Attached files</source>
        <translation>Fichiers joints</translation>
    </message>
    <message>
        <location line="+74"/>
        <source>Go to previous message</source>
        <translation>Aller au message précédent</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Go to next message</source>
        <translation>Aller au message suivant</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>Edit the message</source>
        <translation>Modifier le message</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Re-generate the answer</source>
        <translation>Régénérer la réponse</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Copy the message to clipboard</source>
        <translation>Copier le message dans le presse-papiers</translation>
    </message>
    <message>
        <location line="+54"/>
        <source>Thinking %1</source>
        <translation>En train de réfléchir %1</translation>
    </message>
    <message>
        <location line="+208"/>
        <source>Overwrite File?</source>
        <translation>Écraser le fichier ?</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>The file &quot;%1&quot; already exists.

Do you want to overwrite it?</source>
        <translation>Le fichier « %1 » existe déjà.

Voulez-vous l'écraser ?</translation>
    </message>
    <message>
        <location line="+21"/>
        <source>Save File</source>
        <translation>Enregistrer le fichier</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>All Files (*)</source>
        <translation>Tous les fichiers (*)</translation>
    </message>
    <message>
        <location filename="../llamaconversationsmodel.cpp" line="+73"/>
        <source>Name</source>
        <translation>Nom</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Date</source>
        <translation>Date</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Conversation Id</source>
        <translation>Identifiant de conversation</translation>
    </message>
    <message>
        <location filename="../llamaconversationsview.cpp" line="+111"/>
        <source>Creates a new llama.cpp conversation</source>
        <translation>Crée une nouvelle conversation llama.cpp</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Refresh</source>
        <translation>Actualiser</translation>
    </message>
    <message>
        <location line="+114"/>
        <source>Rename...</source>
        <translation>Renommer...</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Summarize</source>
        <translation>Résumer</translation>
    </message>
    <message>
        <location line="+1"/>
        <location line="+40"/>
        <source>Delete</source>
        <translation>Supprimer</translation>
    </message>
    <message>
        <location line="-39"/>
        <source>Save as Markdown</source>
        <translation>Enregistrer au format Markdown</translation>
    </message>
    <message>
        <location line="+32"/>
        <source>Delete Conversation</source>
        <translation>Supprimer la conversation</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Are you sure you want to delete the conversation:
%1</source>
        <translation>Êtes-vous sûr de vouloir supprimer la conversation : %1</translation>
    </message>
    <message>
        <location line="+74"/>
        <source>Save Conversation as Markdown</source>
        <translation>Enregistrer la conversation au format Markdown</translation>
    </message>
    <message>
        <location line="+12"/>
        <source>Error</source>
        <translation>Erreur</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Cannot write file:
%1</source>
        <translation>Impossible d'écrire dans le fichier : %1</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>llama.cpp Conversations</source>
        <translation>Conversations llama.cpp</translation>
    </message>
    <message>
        <location filename="../llamalocatorfilter.cpp" line="+43"/>
        <source>Create a summary of {selection}</source>
        <translation>Créer un résumé de {sélection}</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Create a commit message for {selection}</source>
        <translation>Créer un message de validation pour {sélection}</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Explain the code in {selection}</source>
        <translation>Expliquer le code dans {sélection}</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Do spell checking and fix any typos in {selection}</source>
        <translation>Vérifier l'orthographe et corriger les fautes de frappe dans {sélection}</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Generate test cases for {selection}. Output only code. No explanations</source>
        <translation>Générer des cas de test pour {sélection}. Sortie de code uniquement. Pas d'explications</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Update translation in {selection}. Provide the full translation file as output</source>
        <translation>Mettre à jour la traduction dans {sélection}. Fournir le fichier de traduction complet en sortie</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>Send the current selection to llama.cpp with a prompt.
Built‑in prompts: %1
You can type any other prompt – they are remembered for next time.</source>
        <translation>Envoyer la sélection actuelle à llama.cpp avec une invite.
Invites intégrées : %1
Vous pouvez taper n'importe quelle autre invite - elles sont mémorisées pour la prochaine fois.</translation>
    </message>
    <message>
        <location filename="../llamamarkdownwidget.cpp" line="+107"/>
        <source>Copy the code below to Clipboard</source>
        <translation>Copier le code ci-dessous dans le presse-papiers</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Save the code below into a file on disk</source>
        <translation>Enregistrer le code ci-dessous dans un fichier sur le disque</translation>
    </message>
    <message>
        <location line="+282"/>
        <location line="+10"/>
        <source>Copy</source>
        <translation>Copier</translation>
    </message>
    <message>
        <location line="-9"/>
        <location line="+10"/>
        <source>Save</source>
        <translation>Enregistrer</translation>
    </message>
    <message>
        <location filename="../llamaplugin.h" line="+118"/>
        <source>New Conversation</source>
        <translation>Nouvelle conversation</translation>
    </message>
    <message>
        <location filename="../llamasearchtoolbar.cpp" line="+22"/>
        <source>Search</source>
        <translation>Rechercher</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Find ...</source>
        <translation>Trouver...</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Previous result</source>
        <translation>Résultat précédent</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Next result</source>
        <translation>Résultat suivant</translation>
    </message>
</context>
</TS>
