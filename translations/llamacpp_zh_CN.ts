<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE TS>
<TS version="2.1" language="zh_CN">
<context>
    <name>LlamaCpp</name>
    <message>
        <location filename="../llamaplugin.cpp" line="+117"/>
        <source>llama.cpp coversation</source>
        <translation>llama.cpp 对话</translation>
    </message>
    <message>
        <location line="+10"/>
        <source>Request llama.cpp Suggestion</source>
        <translation>请求 llama.cpp 建议</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Request llama.cpp suggestion at the current editor&apos;s cursor position.</source>
        <translation>在当前编辑器的光标位置请求 llama.cpp 建议。</translation>
    </message>
    <message>
        <location line="+9"/>
        <source>Ctrl+G</source>
        <translation>Ctrl+G</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Toggle enable/disable llama.cpp</source>
        <translation>切换启用/禁用 llama.cpp</translation>
    </message>
    <message>
        <location line="+10"/>
        <source>Toggle Auto FIM</source>
        <translation>切换自动 FIM</translation>
    </message>
    <message>
        <location line="+16"/>
        <source>Ctrl+Shift+G</source>
        <translation>Ctrl+Shift+G</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Disable llama.cpp.</source>
        <translation>禁用 llama.cpp。</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>Enable llama.cpp.</source>
        <translation>启用 llama.cpp。</translation>
    </message>
    <message>
        <location line="+362"/>
        <source>[llama.cpp] Error fetching fim completion from %1: %2</source>
        <translation>[llama.cpp] 从 %1 获取 fim 补全时出错：%2</translation>
    </message>
    <message>
        <location line="-427"/>
        <location filename="../llamaprojectpanel.cpp" line="+63"/>
        <source>llama.cpp</source>
        <translation>llama.cpp</translation>
    </message>
    <message>
        <location filename="../llamasettings.cpp" line="+18"/>
        <location line="+1"/>
        <source>Enable llama.cpp</source>
        <translation>启用 llama.cpp</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Enables the llama.cpp integration.</source>
        <translation>启用 llama.cpp 集成。</translation>
    </message>
    <message>
        <location line="+18"/>
        <source>Endpoint</source>
        <translation>端点</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Endpoint:</source>
        <translation>端点：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>llama.cpp server endpoint</source>
        <translation>llama.cpp 服务器端点</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>API Key</source>
        <translation>API 密钥</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>API Key:</source>
        <translation>API 密钥：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>llama.cpp server api key (optional)</source>
        <translation>llama.cpp 服务器 API 密钥（可选）</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Prefix Code Lines</source>
        <translation>前缀代码行</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Prefix Code Lines:</source>
        <translation>前缀代码行：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Number of code lines before the cursor location to include in the local prefix.</source>
        <translation>在光标位置之前要包含在本地前缀中的代码行数。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Suffix Code Lines</source>
        <translation>后缀代码行</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Suffix Code Lines:</source>
        <translation>后缀代码行：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Number of code lines after  the cursor location to include in the local suffix.</source>
        <translation>在光标位置之后要包含在本地后缀中的代码行数。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max Token Predictions</source>
        <translation>最大令牌预测数</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Token Predictions:</source>
        <translation>最大令牌预测数：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max number of tokens to predict.</source>
        <translation>要预测的最大令牌数。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Stop Strings</source>
        <translation>停止字符串</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Stop Strings:</source>
        <translation>停止字符串：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Return the result immediately as soon as any of these strings are encountered in the generated text. Separated by semicolons.</source>
        <translation>在生成的文本中遇到这些字符串中的任何一个时立即返回结果。用分号分隔。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Max Prompt Time (ms)</source>
        <translation>最大提示时间（毫秒）</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Prompt Time (ms):</source>
        <translation>最大提示时间（毫秒）：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max alloted time for the prompt processing (TODO: not yet supported).</source>
        <translation>提示处理的最大分配时间（TODO：尚未支持）。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max Predict Time (ms)</source>
        <translation>最大预测时间（毫秒）</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Predict Time (ms):</source>
        <translation>最大预测时间（毫秒）：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max alloted time for the prediction.</source>
        <translation>预测的最大分配时间。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Show Info</source>
        <translation>显示信息</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Show Info:</source>
        <translation>显示信息：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Show extra info about the inference (0 - disabled, 1 - statusline, 2 - inline).</source>
        <translation>显示关于推理的额外信息（0 - 禁用，1 - 状态行，2 - 内联）。</translation>
    </message>
    <message>
        <location line="+3"/>
        <location line="+2"/>
        <source>Auto FIM</source>
        <translation>自动 FIM</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Trigger FIM (Fill-in-the-Middle) completion automatically on cursor movement.</source>
        <translation>在光标移动时自动触发 FIM（填充中间）补全。</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Line Suffix</source>
        <translation>最大行后缀</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Line Suffix:</source>
        <translation>最大行后缀：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Do not auto-trigger FIM completion if there are more than this number of characters to the right of the cursor.</source>
        <translation>如果光标右侧有超过此数量的字符，则不自动触发 FIM 补全。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Max Cache Keys</source>
        <translation>最大缓存键</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Cache Keys:</source>
        <translation>最大缓存键：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max number of cached completions to keep in result_cache.</source>
        <translation>在 result_cache 中保留的最大缓存补全数量。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Ring Chunks</source>
        <translation>环形块</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Ring Chunks:</source>
        <translation>环形块：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Max number of chunks to pass as extra context to the server (0 to disable).</source>
        <translation>要传递给服务器的额外上下文的最大块数（0 表示禁用）。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Chunk Line Size</source>
        <translation>块行大小</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chunk Line Size:</source>
        <translation>块行大小：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max size of the chunks (in number of lines).&lt;br/&gt;&lt;br/&gt;Note: adjust these numbers so that you don&apos;t overrun your context. At ring_n_chunks = 64 and ring_chunk_size = 64 you need ~32k context.</source>
        <translation>块的最大大小（以行数计）。&lt;br/&gt;&lt;br/&gt;注意：调整这些数字以避免超出上下文。在 ring_n_chunks = 64 和 ring_chunk_size = 64 时，您需要 ~32k 上下文。</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Ring Line Scope</source>
        <translation>环形行范围</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Ring Line Scope:</source>
        <translation>环形行范围：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The range around the cursor position (in number of lines) for gathering chunks after FIM.</source>
        <translation>在 FIM 之后收集块的范围（以行数计，在光标位置周围）。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Update Interval (ms)</source>
        <translation>更新间隔（毫秒）</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Update Interval (ms):</source>
        <translation>更新间隔（毫秒）：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>How often to process queued chunks in normal mode.</source>
        <translation>在普通模式下多长时间处理一次排队的块。</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Chat Endpoint</source>
        <translation>聊天端点</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chat Endpoint:</source>
        <translation>聊天端点：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>llama.cpp server chat endpoint</source>
        <translation>llama.cpp 服务器聊天端点</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Chat API Key</source>
        <translation>聊天 API 密钥</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Chat API Key:</source>
        <translation>聊天 API 密钥：</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Set the API Key if you are using --api-key option for the server.</source>
        <translation>如果您使用了服务器的 --api-key 选项，请设置 API 密钥。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>System Message</source>
        <translation>系统消息</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>System Message:</source>
        <translation>系统消息：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Default: none</source>
        <translation>默认：无</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The starting message that defines how model should behave. Will be disabled if left empty.</source>
        <translation>定义模型行为的起始消息。如果为空，将被禁用。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Paste Long Text to File Length</source>
        <translation>将长文本粘贴到文件的长度</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Paste Long Text to File Length:</source>
        <translation>将长文本粘贴到文件的长度：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>On pasting long text, it will be converted to a file. You can control the file length by setting the value of this parameter. Value 0 means disable.</source>
        <translation>在粘贴长文本时，它将被转换为文件。您可以通过设置此参数的值来控制文件长度。值 0 表示禁用。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Samplers</source>
        <translation>采样器</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Samplers:</source>
        <translation>采样器：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>The order at which samplers are applied, in simplified way. Default is &quot;edkypmxt&quot;: dry-&gt;top_k-&gt;typ_p-&gt;top_p-&gt;min_p-&gt;xtc-&gt;temperature</source>
        <translation>采样器应用的顺序，以简化方式表示。默认是 &quot;edkypmxt&quot;: dry-&gt;top_k-&gt;typ_p-&gt;top_p-&gt;min_p-&gt;xtc-&gt;temperature</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Temperature</source>
        <translation>温度</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Temperature:</source>
        <translation>温度：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Controls the randomness of the generated text by affecting the probability distribution of the output tokens. Higher = more random, lower = more focused.</source>
        <translation>通过影响输出令牌的概率分布来控制生成文本的随机性。数值越高越随机，数值越低越集中。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Dynamic Temperature Range</source>
        <translation>动态温度范围</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Dynamic Temperature Range:</source>
        <translation>动态温度范围：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Addon for the temperature sampler. The added value to the range of dynamic temperature, which adjusts probabilities by entropy of tokens.</source>
        <translation>温度采样器的附加组件。添加到动态温度范围的值，根据令牌的熵调整概率。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Dynamic Temperature Exponent</source>
        <translation>动态温度指数</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Dynamic Temperature Exponent:</source>
        <translation>动态温度指数：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Addon for the temperature sampler. Smoothes out the probability redistribution based on the most probable token.</source>
        <translation>温度采样器的附加组件。基于最可能的令牌平滑概率重新分配。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Top K</source>
        <translation>Top K</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Top K:</source>
        <translation>Top K：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Keeps only k top tokens.</source>
        <translation>仅保留前 k 个令牌。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Top P</source>
        <translation>Top P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Top P:</source>
        <translation>Top P：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens to those that together have a cumulative probability of at least p</source>
        <translation>将令牌限制为那些累积概率至少为 p 的令牌</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Min P</source>
        <translation>最小 P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Min P:</source>
        <translation>最小 P：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Limits tokens based on the minimum probability for a token to be considered, relative to the probability of the most likely token.</source>
        <translation>基于令牌的最小概率，相对于最可能令牌的概率，限制令牌。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>XTC Probability</source>
        <translation>XTC 概率</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>XTC Probability:</source>
        <translation>XTC 概率：</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC.</source>
        <translation>XTC 采样器会剔除前几个令牌；此参数控制是否剔除令牌的概率。0 禁用 XTC。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>XTC Threshold</source>
        <translation>XTC 阈值</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>XTC Threshold:</source>
        <translation>XTC 阈值：</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token.</source>
        <translation>XTC 采样器会剔除前几个令牌；此参数控制需要剔除该令牌的令牌概率。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Typical P</source>
        <translation>典型 P</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Typical P:</source>
        <translation>典型 P：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Sorts and limits tokens based on the difference between log-probability and entropy.</source>
        <translation>基于对数概率与熵的差异对令牌进行排序和限制。</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Repeat Last N</source>
        <translation>重复最后 N 个</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Repeat Last N:</source>
        <translation>重复最后 N 个：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Last n tokens to consider for penalizing repetition</source>
        <translation>考虑惩罚重复的最后 n 个令牌</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Repeat Penalty</source>
        <translation>重复惩罚</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Repeat Penalty:</source>
        <translation>重复惩罚：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Controls the repetition of token sequences in the generated text</source>
        <translation>控制生成文本中令牌序列的重复</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Presence Penalty</source>
        <translation>存在惩罚</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Presence Penalty:</source>
        <translation>存在惩罚：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens based on whether they appear in the output or not.</source>
        <translation>基于令牌是否出现在输出中来限制令牌。</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Frequency Penalty</source>
        <translation>频率惩罚</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Frequency Penalty:</source>
        <translation>频率惩罚：</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Limits tokens based on how often they appear in the output.</source>
        <translation>基于令牌在输出中出现的频率来限制令牌。</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Multiplier</source>
        <translation>DRY 乘数</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Multiplier:</source>
        <translation>DRY 乘数：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier.</source>
        <translation>DRY 采样可减少生成文本中的重复，即使是在长上下文中。此参数设置 DRY 采样的乘数。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Base</source>
        <translation>DRY 基础</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Base:</source>
        <translation>DRY 基础：</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value.</source>
        <translation>DRY 采样可减少生成文本中的重复，即使是在长上下文中。此参数设置 DRY 采样的基础值。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Allowed Length</source>
        <translation>DRY 允许长度</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Allowed Length:</source>
        <translation>DRY 允许长度：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling.</source>
        <translation>DRY 采样可减少生成文本中的重复，即使是在长上下文中。此参数设置 DRY 采样的允许长度。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>DRY Penalty Last N</source>
        <translation>DRY 最后 N 个惩罚</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY Penalty Last N:</source>
        <translation>DRY 最后 N 个惩罚：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens.</source>
        <translation>DRY 采样可减少生成文本中的重复，即使是在长上下文中。此参数为最后 n 个令牌设置 DRY 惩罚。</translation>
    </message>
    <message>
        <location line="+5"/>
        <source>Max Tokens</source>
        <translation>最大令牌数</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Max Tokens:</source>
        <translation>最大令牌数：</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>The maximum number of token per output. -1 means no limit.</source>
        <translation>每个输出的最大令牌数。-1 表示无限制。</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Custom JSON config</source>
        <translation>自定义 JSON 配置</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Custom JSON config:</source>
        <translation>自定义 JSON 配置：</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Custom JSON string of extra parameters.</source>
        <translation>额外参数的自定义 JSON 字符串。</translation>
    </message>
    <message>
        <location line="+4"/>
        <location line="+2"/>
        <source>Show Tokens Per Second</source>
        <translation>显示每秒令牌数</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Show tokens per second in the chat UI.</source>
        <translation>在聊天 UI 中显示每秒令牌数。</translation>
    </message>
    <message>
        <location filename="../llamachateditor.cpp" line="+219"/>
        <source>Search in chat</source>
        <translation>在聊天中搜索</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Next search result</source>
        <translation>下一搜索结果</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Previous search result</source>
        <translation>上一搜索结果</translation>
    </message>
    <message>
        <location line="+44"/>
        <source>Model Path: %1</source>
        <translation>模型路径：%1</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Context: %L1</source>
        <translation>上下文：%L1</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Vision: %1</source>
        <translation>视觉：%1</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>yes</source>
        <translation>是</translation>
    </message>
    <message>
        <location line="+0"/>
        <source>no</source>
        <translation>否</translation>
    </message>
    <message>
        <location line="+35"/>
        <source>Follow‑up questions:</source>
        <translation>后续问题：</translation>
    </message>
    <message>
        <location line="+477"/>
        <source>Speed: %1 t/s</source>
        <translation>速度：%1 t/s</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>&lt;b&gt;Prompt:&lt;/b&gt;&lt;br&gt;Tokens: %1&lt;br&gt;Time: %2 ms&lt;br&gt;Speed: %3 t/s&lt;br&gt;&lt;br&gt;&lt;b&gt;Generation:&lt;/b&gt;&lt;br&gt;Tokens: %4&lt;br&gt;Time: %5 ms&lt;br&gt;Speed: %6 t/s</source>
        <translation>&lt;b&gt;提示：&lt;/b&gt;&lt;br&gt;令牌：%1&lt;br&gt;时间：%2 ms&lt;br&gt;速度：%3 t/s&lt;br&gt;&lt;br&gt;&lt;b&gt;生成：&lt;/b&gt;&lt;br&gt;令牌：%4&lt;br&gt;时间：%5 ms&lt;br&gt;速度：%6 t/s</translation>
    </message>
    <message>
        <location line="+43"/>
        <source>LlamaCpp Chat Editor</source>
        <translation>LlamaCpp 聊天编辑器</translation>
    </message>
    <message>
        <location filename="../llamachatinput.cpp" line="+73"/>
        <source>Type a message (Shift+Enter for new line)</source>
        <translation>输入消息（Shift+Enter 换行）</translation>
    </message>
    <message>
        <location line="+12"/>
        <source>Attach file</source>
        <translation>附加文件</translation>
    </message>
    <message>
        <location line="+54"/>
        <source>Stop assistant answer generation</source>
        <translation>停止助手答案生成</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Send message to assistant</source>
        <translation>向助手发送消息</translation>
    </message>
    <message>
        <location filename="../llamachatmessage.cpp" line="+71"/>
        <location line="+203"/>
        <source>Thought Process</source>
        <translation>思考过程</translation>
    </message>
    <message>
        <location line="-202"/>
        <source>Click to expand / hide the thought process</source>
        <translation>点击展开/隐藏思考过程</translation>
    </message>
    <message>
        <location line="+41"/>
        <source>Attached files</source>
        <translation>已附加文件</translation>
    </message>
    <message>
        <location line="+74"/>
        <source>Go to previous message</source>
        <translation>转到上一条消息</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Go to next message</source>
        <translation>转到下一条消息</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>Edit the message</source>
        <translation>编辑消息</translation>
    </message>
    <message>
        <location line="+6"/>
        <source>Re-generate the answer</source>
        <translation>重新生成答案</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Copy the message to clipboard</source>
        <translation>复制消息到剪贴板</translation>
    </message>
    <message>
        <location line="+54"/>
        <source>Thinking %1</source>
        <translation>正在思考 %1</translation>
    </message>
    <message>
        <location line="+208"/>
        <source>Overwrite File?</source>
        <translation>覆盖文件？</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>The file &quot;%1&quot; already exists.

Do you want to overwrite it?</source>
        <translation>文件 &quot;%1&quot; 已经存在。

要覆盖它吗？</translation>
    </message>
    <message>
        <location line="+21"/>
        <source>Save File</source>
        <translation>保存文件</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>All Files (*)</source>
        <translation>所有文件 (*)</translation>
    </message>
    <message>
        <location filename="../llamaconversationsmodel.cpp" line="+73"/>
        <source>Name</source>
        <translation>名称</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Date</source>
        <translation>日期</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Conversation Id</source>
        <translation>会话 ID</translation>
    </message>
    <message>
        <location filename="../llamaconversationsview.cpp" line="+111"/>
        <source>Creates a new llama.cpp conversation</source>
        <translation>创建新的 llama.cpp 对话</translation>
    </message>
    <message>
        <location line="+4"/>
        <source>Refresh</source>
        <translation>刷新</translation>
    </message>
    <message>
        <location line="+114"/>
        <source>Rename...</source>
        <translation>重命名...</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Summarize</source>
        <translation>总结</translation>
    </message>
    <message>
        <location line="+1"/>
        <location line="+40"/>
        <source>Delete</source>
        <translation>删除</translation>
    </message>
    <message>
        <location line="-39"/>
        <source>Save as Markdown</source>
        <translation>保存为 Markdown</translation>
    </message>
    <message>
        <location line="+32"/>
        <source>Delete Conversation</source>
        <translation>删除对话</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Are you sure you want to delete the conversation:
%1</source>
        <translation>您确定要删除对话：
%1</translation>
    </message>
    <message>
        <location line="+74"/>
        <source>Save Conversation as Markdown</source>
        <translation>将对话保存为 Markdown</translation>
    </message>
    <message>
        <location line="+12"/>
        <source>Error</source>
        <translation>错误</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Cannot write file:
%1</source>
        <translation>无法写入文件：
%1</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>llama.cpp Conversations</source>
        <translation>llama.cpp 对话</translation>
    </message>
    <message>
        <location filename="../llamalocatorfilter.cpp" line="+43"/>
        <source>Create a summary of {selection}</source>
        <translation>创建 {selection} 的摘要</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Create a commit message for {selection}</source>
        <translation>为 {selection} 创建提交消息</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Explain the code in {selection}</source>
        <translation>解释 {selection} 中的代码</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Do spell checking and fix any typos in {selection}</source>
        <translation>对 {selection} 进行拼写检查并修正任何拼写错误</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Generate test cases for {selection}. Output only code. No explanations</source>
        <translation>为 {selection} 生成测试用例。仅输出代码，无说明</translation>
    </message>
    <message>
        <location line="+1"/>
        <source>Update translation in {selection}. Provide the full translation file as output</source>
        <translation>更新 {selection} 中的翻译。将完整的翻译文件作为输出提供</translation>
    </message>
    <message>
        <location line="+11"/>
        <source>Send the current selection to llama.cpp with a prompt.
Built‑in prompts: %1
You can type any other prompt – they are remembered for next time.</source>
        <translation>使用提示将当前选择发送到 llama.cpp。
内置提示：%1
您可以输入任何其他提示 - 它们将被记住以备下次使用。</translation>
    </message>
    <message>
        <location filename="../llamamarkdownwidget.cpp" line="+107"/>
        <source>Copy the code below to Clipboard</source>
        <translation>将下面的代码复制到剪贴板</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Save the code below into a file on disk</source>
        <translation>将下面的代码保存到磁盘上的文件</translation>
    </message>
    <message>
        <location line="+282"/>
        <location line="+10"/>
        <source>Copy</source>
        <translation>复制</translation>
    </message>
    <message>
        <location line="-9"/>
        <location line="+10"/>
        <source>Save</source>
        <translation>保存</translation>
    </message>
    <message>
        <location filename="../llamaplugin.h" line="+118"/>
        <source>New Conversation</source>
        <translation>新对话</translation>
    </message>
    <message>
        <location filename="../llamasearchtoolbar.cpp" line="+22"/>
        <source>Search</source>
        <translation>搜索</translation>
    </message>
    <message>
        <location line="+7"/>
        <source>Find ...</source>
        <translation>查找 ...</translation>
    </message>
    <message>
        <location line="+3"/>
        <source>Previous result</source>
        <translation>上一结果</translation>
    </message>
    <message>
        <location line="+2"/>
        <source>Next result</source>
        <translation>下一结果</translation>
    </message>
</context>
</TS>
